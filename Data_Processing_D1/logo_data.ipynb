{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import os\n",
    "\n",
    "\n",
    "DEFAULT_TZ = pytz.FixedOffset(540)  # GMT+09:00; Asia/Seoul\n",
    "\n",
    "PATH_DATA = 'data/D'\n",
    "PATH_ESM = os.path.join(PATH_DATA, 'EsmResponse.csv')\n",
    "PATH_PARTICIPANT = os.path.join(PATH_DATA, 'UserInfo.csv')\n",
    "PATH_SENSOR = os.path.join(PATH_DATA, 'Sensor')\n",
    "\n",
    "PATH_INTERMEDIATE = os.path.join('data/intermediate')\n",
    "PATH_SAVE = '/home/user/Collab/MT/logo/3_clusters/data_MT'\n",
    "\n",
    "DATA_TYPES = {\n",
    "    'Acceleration': 'ACC',\n",
    "    'AmbientLight': 'AML',\n",
    "    'Calorie': 'CAL',\n",
    "    'Distance': 'DST',\n",
    "    'EDA': 'EDA',\n",
    "    'HR': 'HRT',\n",
    "    'RRI': 'RRI',\n",
    "    'SkinTemperature': 'SKT',\n",
    "    'StepCount': 'STP',\n",
    "    'UltraViolet': 'ULV',\n",
    "    'ActivityEvent': 'ACE',\n",
    "    'ActivityTransition': 'ACT',\n",
    "    'AppUsageEvent': 'APP',\n",
    "    'BatteryEvent': 'BAT',\n",
    "    'CallEvent': 'CAE',\n",
    "    'Connectivity': 'CON',\n",
    "    'DataTraffic': 'DAT',\n",
    "    'InstalledApp': 'INS',\n",
    "    'Location': 'LOC',\n",
    "    'MediaEvent': 'MED',\n",
    "    'MessageEvent': 'MSG',\n",
    "    'WiFi': 'WIF',\n",
    "    'ScreenEvent': 'SCR',\n",
    "    'RingerModeEvent': 'RNG',\n",
    "    'ChargeEvent': 'CHG',\n",
    "    'PowerSaveEvent': 'PWS',\n",
    "    'OnOffEvent': 'ONF'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import cloudpickle\n",
    "import ray\n",
    "from datetime import datetime\n",
    "from contextlib import contextmanager\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "\n",
    "def load(path: str):\n",
    "    with open(path, mode='rb') as f:\n",
    "        return cloudpickle.load(f)\n",
    "\n",
    "    \n",
    "def dump(obj, path: str):\n",
    "    with open(path, mode='wb') as f:\n",
    "        cloudpickle.dump(obj, f)\n",
    "        \n",
    "    \n",
    "def log(msg: any):\n",
    "    print('[{}] {}'.format(datetime.now().strftime('%y-%m-%d %H:%M:%S'), msg))\n",
    "\n",
    "\n",
    "def summary(x):\n",
    "    x = np.asarray(x)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        n = len(x)\n",
    "        # Here, uppercase np.dtype.kind corresponds to non-numeric data.\n",
    "        # Also, we view the boolean data as dichotomous categorical data.\n",
    "        if x.dtype.kind.isupper() or x.dtype.kind == 'b': \n",
    "            cnt = pd.Series(x).value_counts(dropna=False)\n",
    "            card = len(cnt)\n",
    "            cnt = cnt[:20]                \n",
    "            cnt_str = ', '.join([f'{u}:{c}' for u, c in zip(cnt.index, cnt)])\n",
    "            if card > 30:\n",
    "                cnt_str = f'{cnt_str}, ...'\n",
    "            return {\n",
    "                'n': n,\n",
    "                'cardinality': card,\n",
    "                'value_count': cnt_str\n",
    "            }\n",
    "        else: \n",
    "            x_nan = x[np.isnan(x)]\n",
    "            x_norm = x[~np.isnan(x)]\n",
    "            \n",
    "            tot = np.sum(x_norm)\n",
    "            m = np.mean(x_norm)\n",
    "            me = np.median(x_norm)\n",
    "            s = np.std(x_norm, ddof=1)\n",
    "            l, u = np.min(x_norm), np.max(x)\n",
    "            conf_l, conf_u = st.t.interval(0.95, len(x_norm) - 1, loc=m, scale=st.sem(x_norm))\n",
    "            n_nan = len(x_nan)\n",
    "            \n",
    "            return {\n",
    "                'n': n,\n",
    "                'sum': tot,\n",
    "                'mean': m,\n",
    "                'SD': s,\n",
    "                'med': me,\n",
    "                'range': (l, u),\n",
    "                'conf.': (conf_l, conf_u),\n",
    "                'nan_count': n_nan\n",
    "            }\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def on_ray(*args, **kwargs):\n",
    "    try:\n",
    "        if ray.is_initialized():\n",
    "            ray.shutdown()\n",
    "        ray.init(*args, **kwargs)\n",
    "        yield None\n",
    "    finally:\n",
    "        ray.shutdown()\n",
    "\n",
    "transform = {\n",
    "    'GAME': 'ENTER',\n",
    "    'GAME_TRIVIA': 'ENTER',\n",
    "    'GAME_CASINO': 'ENTER',\n",
    "    'GAME-ACTION': 'ENTER',\n",
    "    'GAME_SPORTS': 'ENTER',\n",
    "    'GAME_PUZZLE': 'ENTER',\n",
    "    'GAME_SIMULATION': 'ENTER',\n",
    "    'GAME_STRATEGY': 'ENTER',\n",
    "    'GAME_ROLE_PLAYING': 'ENTER',\n",
    "    'GAME_ACTION': 'ENTER',\n",
    "    'GAME_ARCADE': 'ENTER',\n",
    "    'GAME_RACING': 'ENTER',\n",
    "    'GAME_CASUAL': 'ENTER',\n",
    "    'GAME_MUSIC': 'ENTER',\n",
    "    'GAME_CARD': 'ENTER',\n",
    "    'GAME_ADVENTURE': 'ENTER',\n",
    "    'GAME_BOARD': 'ENTER',\n",
    "    'GAME_EDUCATIONAL': 'ENTER',\n",
    "    'GAME_RACING': 'ENTER',\n",
    "    'PHOTOGRAPHY': 'ENTER',\n",
    "    'ENTERTAINMENT': 'ENTER',\n",
    "    'SPORTS': 'ENTER',\n",
    "    'MUSIC_AND_AUDIO': 'ENTER',\n",
    "    'COMICS': 'ENTER',\n",
    "    'VIDEO_PLAYERS_AND_EDITORS': 'ENTER',\n",
    "    'VIDEO_PLAYERS': 'ENTER',\n",
    "    'ART_AND_DESIGN': 'ENTER',\n",
    "    'TRAVEL_AND_LOCAL': 'INFO',\n",
    "    'FOOD_AND_DRINK': 'INFO',\n",
    "    'NEWS_AND_MAGAZINES': 'INFO',\n",
    "    'MAPS_AND_NAVIGATION': 'INFO',\n",
    "    'WEATHER': 'INFO',\n",
    "    'HOUSE_AND_HOME': 'INFO',\n",
    "    'BOOKS_AND_REFERENCE': 'INFO',\n",
    "    'SHOPPING': 'INFO',\n",
    "    'LIBRARIES_AND_DEMO': 'INFO',\n",
    "    'BEAUTY': 'INFO',\n",
    "    'AUTO_AND_VEHICLES': 'INFO',\n",
    "    'LIFESTYLE': 'INFO',\n",
    "    'PERSONALIZATION': 'SYSTEM',\n",
    "    'TOOLS': 'SYSTEM',\n",
    "    'COMMUNICATION': 'SOCIAL',\n",
    "    'SOCIAL': 'SOCIAL',\n",
    "    'DATING': 'SOCIAL',\n",
    "    'PARENTING':'SOCIAL',\n",
    "    'FINANCE': 'WORK',\n",
    "    'BUSINESS': 'WORK',\n",
    "    'PRODUCTIVITY': 'WORK',\n",
    "    'EDUCATION': 'WORK',\n",
    "    'HEALTH_AND_FITNESS': 'HEALTH',\n",
    "    'MEDICAL': 'HEALTH',\n",
    "    'SYSTEM': 'SYSTEM',\n",
    "    'MISC': 'SYSTEM', # ABC logger\n",
    "     None: 'UNKNOWN',\n",
    "    'UNKNOWN':'UNKNOWN'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = os.path.join(PATH_INTERMEDIATE, 'stress-fixed.pkl')\n",
    "X, y, groups, t, datetimes = load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTICIPANTS = pd.read_csv(os.path.join(PATH_INTERMEDIATE, 'PARTICIPANT_INFO.csv'),index_col = 'pcode')\n",
    "PINFO = PARTICIPANTS.assign(\n",
    "    BFI_OPN=lambda x: x['openness'],\n",
    "    BFI_CON=lambda x: x['conscientiousness'],\n",
    "    BFI_NEU=lambda x: x['neuroticism'],\n",
    "    BFI_EXT=lambda x: x['extraversion'],\n",
    "    BFI_AGR=lambda x: x['agreeableness'],\n",
    ")[[\n",
    "    'BFI_OPN', 'BFI_CON', 'BFI_NEU', 'BFI_EXT', 'BFI_AGR'\n",
    "]]\n",
    "PINFO = pd.get_dummies(PINFO, prefix_sep='=', dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BFI_OPN</th>\n",
       "      <th>BFI_CON</th>\n",
       "      <th>BFI_NEU</th>\n",
       "      <th>BFI_EXT</th>\n",
       "      <th>BFI_AGR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P02</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P03</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P04</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P05</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P76</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P77</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P78</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P79</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P80</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BFI_OPN  BFI_CON  BFI_NEU  BFI_EXT  BFI_AGR\n",
       "pcode                                             \n",
       "P01         11       11        3        4       13\n",
       "P02         14        5       12       14        5\n",
       "P03         10       15        8        7       11\n",
       "P04         12       11        8        6       11\n",
       "P05         10       11       13       10        6\n",
       "...        ...      ...      ...      ...      ...\n",
       "P76          8        8       12        6        8\n",
       "P77         11       12        7       11       10\n",
       "P78         12       11        9       12       10\n",
       "P79          9       10        7       12       11\n",
       "P80         13        7        5        4       12\n",
       "\n",
       "[77 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       BFI_OPN  BFI_CON  BFI_NEU  BFI_EXT  BFI_AGR\n",
      "pcode                                             \n",
      "P80         13        7        5        4       12\n",
      "       BFI_OPN  BFI_CON  BFI_NEU  BFI_EXT  BFI_AGR\n",
      "pcode                                             \n",
      "P01         11       11        3        4       13\n",
      "P02         14        5       12       14        5\n",
      "P03         10       15        8        7       11\n",
      "P04         12       11        8        6       11\n",
      "P05         10       11       13       10        6\n",
      "...        ...      ...      ...      ...      ...\n",
      "P76          8        8       12        6        8\n",
      "P77         11       12        7       11       10\n",
      "P78         12       11        9       12       10\n",
      "P79          9       10        7       12       11\n",
      "P80         13        7        5        4       12\n",
      "\n",
      "[77 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = PINFO[PINFO.duplicated()]\n",
    "\n",
    "print(duplicate_rows)\n",
    "print(PINFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_PROC = pd.read_csv(os.path.join(PATH_INTERMEDIATE, 'LABELS_PROC.csv'), index_col=['pcode','timestamp'],parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First timestamp: 2019-04-30 10:03:28+09:00\n",
      "Last timestamp: 2019-05-22 22:02:03+09:00\n"
     ]
    }
   ],
   "source": [
    "_df =LABELS_PROC\n",
    "_df.reset_index(level='timestamp', inplace=True)\n",
    "print('First timestamp:', _df['timestamp'].min())\n",
    "print('Last timestamp:', _df['timestamp'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            min                       max\n",
      "pcode                                                    \n",
      "P01   2019-05-08 10:29:46+09:00 2019-05-14 21:12:31+09:00\n",
      "P02   2019-05-08 10:52:29+09:00 2019-05-14 21:13:14+09:00\n",
      "P03   2019-05-08 11:13:13+09:00 2019-05-14 20:23:23+09:00\n",
      "P05   2019-05-08 10:40:49+09:00 2019-05-14 21:59:16+09:00\n",
      "P06   2019-05-08 10:32:09+09:00 2019-05-14 21:56:51+09:00\n",
      "P08   2019-05-08 10:42:48+09:00 2019-05-14 21:12:32+09:00\n",
      "P09   2019-05-08 13:44:51+09:00 2019-05-14 20:31:01+09:00\n",
      "P10   2019-05-08 10:40:26+09:00 2019-05-14 15:13:12+09:00\n",
      "P12   2019-05-09 14:18:30+09:00 2019-05-14 21:09:22+09:00\n",
      "P13   2019-05-08 10:30:38+09:00 2019-05-14 21:51:35+09:00\n",
      "P15   2019-05-08 12:09:34+09:00 2019-05-14 19:44:17+09:00\n",
      "P19   2019-05-08 10:41:14+09:00 2019-05-14 22:01:12+09:00\n",
      "P21   2019-05-08 15:49:36+09:00 2019-05-14 21:43:22+09:00\n",
      "P23   2019-05-08 10:20:41+09:00 2019-05-14 18:13:07+09:00\n",
      "P26   2019-05-08 10:11:53+09:00 2019-05-14 21:59:17+09:00\n",
      "P28   2019-05-08 10:32:33+09:00 2019-05-14 21:02:23+09:00\n",
      "P30   2019-05-16 11:19:31+09:00 2019-05-22 21:13:43+09:00\n",
      "P31   2019-05-16 20:27:22+09:00 2019-05-22 21:16:43+09:00\n",
      "P32   2019-05-16 10:24:29+09:00 2019-05-22 22:02:03+09:00\n",
      "P33   2019-05-16 13:39:20+09:00 2019-05-22 21:55:18+09:00\n",
      "P35   2019-05-16 11:24:33+09:00 2019-05-22 20:30:55+09:00\n",
      "P39   2019-05-16 13:03:07+09:00 2019-05-22 22:01:32+09:00\n",
      "P40   2019-05-16 10:12:07+09:00 2019-05-22 19:29:36+09:00\n",
      "P42   2019-05-16 12:15:19+09:00 2019-05-22 21:58:36+09:00\n",
      "P45   2019-05-16 10:18:26+09:00 2019-05-22 20:23:47+09:00\n",
      "P47   2019-05-16 11:30:01+09:00 2019-05-22 21:07:42+09:00\n",
      "P48   2019-05-16 10:33:43+09:00 2019-05-22 16:01:35+09:00\n",
      "P49   2019-05-16 12:55:30+09:00 2019-05-22 21:05:33+09:00\n",
      "P50   2019-05-16 11:33:42+09:00 2019-05-22 21:55:33+09:00\n",
      "P51   2019-05-16 13:40:37+09:00 2019-05-22 21:58:33+09:00\n",
      "P52   2019-05-16 10:28:39+09:00 2019-05-22 16:37:37+09:00\n",
      "P53   2019-05-16 12:37:28+09:00 2019-05-22 21:52:00+09:00\n",
      "P55   2019-04-30 12:46:38+09:00 2019-05-06 21:54:19+09:00\n",
      "P57   2019-04-30 15:12:40+09:00 2019-05-06 21:14:00+09:00\n",
      "P60   2019-04-30 18:09:31+09:00 2019-05-06 21:54:30+09:00\n",
      "P61   2019-04-30 10:42:35+09:00 2019-05-06 21:53:25+09:00\n",
      "P66   2019-04-30 11:56:09+09:00 2019-05-06 22:00:33+09:00\n",
      "P67   2019-04-30 12:56:32+09:00 2019-05-06 21:04:47+09:00\n",
      "P69   2019-04-30 13:40:13+09:00 2019-05-06 21:56:57+09:00\n",
      "P70   2019-04-30 12:12:01+09:00 2019-05-06 21:07:24+09:00\n",
      "P72   2019-04-30 10:03:28+09:00 2019-05-06 21:12:56+09:00\n",
      "P75   2019-04-30 10:26:59+09:00 2019-05-06 19:00:15+09:00\n",
      "P76   2019-04-30 10:39:33+09:00 2019-05-06 21:57:35+09:00\n",
      "P77   2019-04-30 11:18:30+09:00 2019-05-05 21:57:53+09:00\n",
      "P78   2019-04-30 12:14:24+09:00 2019-05-06 21:57:12+09:00\n",
      "P79   2019-04-30 16:40:52+09:00 2019-05-06 22:01:20+09:00\n",
      "P80   2019-05-01 10:30:08+09:00 2019-05-06 21:11:41+09:00\n"
     ]
    }
   ],
   "source": [
    "time_ranges = _df.groupby('pcode')['timestamp'].agg(['min', 'max'])\n",
    "print(time_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P01',\n",
       " 'P02',\n",
       " 'P03',\n",
       " 'P05',\n",
       " 'P06',\n",
       " 'P08',\n",
       " 'P09',\n",
       " 'P10',\n",
       " 'P12',\n",
       " 'P13',\n",
       " 'P15',\n",
       " 'P19',\n",
       " 'P21',\n",
       " 'P23',\n",
       " 'P26',\n",
       " 'P28',\n",
       " 'P30',\n",
       " 'P31',\n",
       " 'P32',\n",
       " 'P33',\n",
       " 'P35',\n",
       " 'P39',\n",
       " 'P40',\n",
       " 'P42',\n",
       " 'P45',\n",
       " 'P47',\n",
       " 'P48',\n",
       " 'P49',\n",
       " 'P50',\n",
       " 'P51',\n",
       " 'P52',\n",
       " 'P53',\n",
       " 'P55',\n",
       " 'P57',\n",
       " 'P60',\n",
       " 'P61',\n",
       " 'P66',\n",
       " 'P67',\n",
       " 'P69',\n",
       " 'P70',\n",
       " 'P72',\n",
       " 'P75',\n",
       " 'P76',\n",
       " 'P77',\n",
       " 'P78',\n",
       " 'P79',\n",
       " 'P80'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pid = set(LABELS_PROC.index.get_level_values('pcode').values)\n",
    "list_pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BFI_OPN    47\n",
       "BFI_CON    47\n",
       "BFI_NEU    47\n",
       "BFI_EXT    47\n",
       "BFI_AGR    47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINFO_valid = PINFO.loc[PINFO.index.isin(list_pid)]\n",
    "PINFO_valid.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       BFI_OPN  BFI_CON  BFI_NEU  BFI_EXT  BFI_AGR\n",
      "pcode                                             \n",
      "P80         13        7        5        4       12\n",
      "       BFI_OPN  BFI_CON  BFI_NEU  BFI_EXT  BFI_AGR\n",
      "pcode                                             \n",
      "P01         11       11        3        4       13\n",
      "P02         14        5       12       14        5\n",
      "P03         10       15        8        7       11\n",
      "P05         10       11       13       10        6\n",
      "P06          3        6       11        3        6\n",
      "P08         10        8        9        9       12\n",
      "P09         12       12        4       11        9\n",
      "P10          6        7        9        9       11\n",
      "P12          9       12        7        7       12\n",
      "P13          5       12        3       12       13\n",
      "P15          6       12        5        6       11\n",
      "P19         12       13        3        9       10\n",
      "P21         12        5        8        8        8\n",
      "P23         13       12        6        9       14\n",
      "P26         13        8        6       11       10\n",
      "P28          6        9        8        7       11\n",
      "P30          7        9       14        9       14\n",
      "P31          9       10        9        9       10\n",
      "P32          9       14       10        7       12\n",
      "P33          8       14        6       13        5\n",
      "P35          6       12       13        3        8\n",
      "P39         12       11        7        8        7\n",
      "P40          7       12        6        7       11\n",
      "P42          7       10        9       13       10\n",
      "P45         11        9        6       10        6\n",
      "P47          8       12       11        7       12\n",
      "P48         11       11       10        8       11\n",
      "P49         11       11        9       10        8\n",
      "P50          8       12        5        9       11\n",
      "P51          6        9        9        4       13\n",
      "P52         13       10        6       10       13\n",
      "P53         13        7        5        4       12\n",
      "P55         15       10       10        9       10\n",
      "P57          9       13        7        8       12\n",
      "P60         15       10        4        6       13\n",
      "P61         10       11        6       11       13\n",
      "P66          8       10        8        8       10\n",
      "P67         12        9        5       12        9\n",
      "P69          3        6       10        9        7\n",
      "P70         12       10        8        8        7\n",
      "P72          4        9       12       12        7\n",
      "P75         12       12        4        5        7\n",
      "P76          8        8       12        6        8\n",
      "P77         11       12        7       11       10\n",
      "P78         12       11        9       12       10\n",
      "P79          9       10        7       12       11\n",
      "P80         13        7        5        4       12\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = PINFO_valid[PINFO_valid.duplicated()]\n",
    "\n",
    "print(duplicate_rows)\n",
    "print(PINFO_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the features into different categories\n",
    "feat_current = X.loc[:,[('#VAL' in str(x)) or ('ESM#LastLabel' in str(x)) for x in X.keys()]]  \n",
    "feat_dsc = X.loc[:,[('#DSC' in str(x))  for x in X.keys()]]  \n",
    "feat_yesterday = X.loc[:,[('Yesterday' in str(x))  for x in X.keys()]]  \n",
    "feat_today = X.loc[:,[('Today' in str(x))  for x in X.keys()]]  \n",
    "feat_sleep = X.loc[:,[('Sleep' in str(x))  for x in X.keys()]]  \n",
    "feat_time = X.loc[:,[('Time' in str(x))  for x in X.keys()]]  \n",
    "feat_pif = X.loc[:,[('PIF' in str(x))  for x in X.keys()]]  \n",
    "feat_ImmediatePast = X.loc[:,[('ImmediatePast_15' in str(x))  for x in X.keys()]]\n",
    "#Divide the time window features into sensor/past stress label\n",
    "feat_current_sensor = X.loc[:,[('#VAL' in str(x))  for x in X.keys()]]  \n",
    "feat_current_ESM = X.loc[:,[('ESM#LastLabel' in str(x)) for x in X.keys()]]  \n",
    "feat_ImmediatePast_sensor = feat_ImmediatePast.loc[:,[('ESM' not in str(x)) for x in feat_ImmediatePast.keys()]]  \n",
    "feat_ImmediatePast_ESM = feat_ImmediatePast.loc[:,[('ESM'  in str(x)) for x in feat_ImmediatePast.keys()]]  \n",
    "feat_today_sensor = feat_today.loc[:,[('ESM' not in str(x))  for x in feat_today.keys()]]  \n",
    "feat_today_ESM = feat_today.loc[:,[('ESM'  in str(x)) for x in feat_today.keys()]]  \n",
    "feat_yesterday_sensor = feat_yesterday.loc[:,[('ESM' not in str(x)) for x in feat_yesterday.keys()]]  \n",
    "feat_yesterday_ESM = feat_yesterday.loc[:,[('ESM'  in str(x)) for x in feat_yesterday.keys()]]\n",
    "#Prepare the final feature set\n",
    "feat_baseline = pd.concat([ feat_time,feat_dsc,feat_current_sensor, feat_ImmediatePast_sensor],axis=1)\n",
    "feat_final = pd.concat([feat_baseline ], axis=1)\n",
    "X = feat_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time#DOW=MON</th>\n",
       "      <th>Time#DOW=TUE</th>\n",
       "      <th>Time#DOW=WED</th>\n",
       "      <th>Time#DOW=THU</th>\n",
       "      <th>Time#DOW=FRI</th>\n",
       "      <th>Time#DOW=SAT</th>\n",
       "      <th>Time#DOW=SUN</th>\n",
       "      <th>Time#WKD=Y</th>\n",
       "      <th>Time#WKD=N</th>\n",
       "      <th>Time#HRN=DAWN</th>\n",
       "      <th>...</th>\n",
       "      <th>ONF#ASC##ImmediatePast_15</th>\n",
       "      <th>ONF#RLV_SUP#ImmediatePast_15</th>\n",
       "      <th>MED_VID#AVG#ImmediatePast_15</th>\n",
       "      <th>MED_VID#STD#ImmediatePast_15</th>\n",
       "      <th>MED_VID#SKW#ImmediatePast_15</th>\n",
       "      <th>MED_VID#KUR#ImmediatePast_15</th>\n",
       "      <th>MED_VID#ASC#ImmediatePast_15</th>\n",
       "      <th>MED_VID#BEP#ImmediatePast_15</th>\n",
       "      <th>MED_VID#MED#ImmediatePast_15</th>\n",
       "      <th>MED_VID#TSC#ImmediatePast_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.493710</td>\n",
       "      <td>-0.32914</td>\n",
       "      <td>2.143928</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.414800</td>\n",
       "      <td>-0.608135</td>\n",
       "      <td>0.608135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.493710</td>\n",
       "      <td>-0.32914</td>\n",
       "      <td>2.143928</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.414800</td>\n",
       "      <td>-0.608135</td>\n",
       "      <td>0.608135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.493710</td>\n",
       "      <td>-0.32914</td>\n",
       "      <td>2.143928</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.414800</td>\n",
       "      <td>-0.608135</td>\n",
       "      <td>0.608135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.493710</td>\n",
       "      <td>-0.32914</td>\n",
       "      <td>2.143928</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.414800</td>\n",
       "      <td>-0.608135</td>\n",
       "      <td>0.608135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.493710</td>\n",
       "      <td>-0.32914</td>\n",
       "      <td>2.143928</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.373210</td>\n",
       "      <td>-0.414800</td>\n",
       "      <td>-0.608135</td>\n",
       "      <td>0.608135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>-0.301735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.514315</td>\n",
       "      <td>-0.546859</td>\n",
       "      <td>-0.378455</td>\n",
       "      <td>-0.448067</td>\n",
       "      <td>2.184325</td>\n",
       "      <td>1.377054</td>\n",
       "      <td>-1.377054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145865</td>\n",
       "      <td>1.242816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>3.243652</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.514315</td>\n",
       "      <td>-0.546859</td>\n",
       "      <td>-0.378455</td>\n",
       "      <td>-0.448067</td>\n",
       "      <td>-0.448067</td>\n",
       "      <td>-0.710737</td>\n",
       "      <td>0.710737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145865</td>\n",
       "      <td>1.242816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>3.243652</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.514315</td>\n",
       "      <td>-0.546859</td>\n",
       "      <td>-0.378455</td>\n",
       "      <td>-0.448067</td>\n",
       "      <td>-0.448067</td>\n",
       "      <td>-0.710737</td>\n",
       "      <td>0.710737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145865</td>\n",
       "      <td>1.242816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>3.243652</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.514315</td>\n",
       "      <td>-0.546859</td>\n",
       "      <td>-0.378455</td>\n",
       "      <td>-0.448067</td>\n",
       "      <td>-0.448067</td>\n",
       "      <td>-0.710737</td>\n",
       "      <td>0.710737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145865</td>\n",
       "      <td>-0.805437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>3.243652</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.514315</td>\n",
       "      <td>-0.546859</td>\n",
       "      <td>-0.378455</td>\n",
       "      <td>-0.448067</td>\n",
       "      <td>-0.448067</td>\n",
       "      <td>-0.710737</td>\n",
       "      <td>0.710737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145865</td>\n",
       "      <td>-0.805437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2619 rows × 571 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time#DOW=MON  Time#DOW=TUE  Time#DOW=WED  Time#DOW=THU  Time#DOW=FRI  \\\n",
       "0        -0.493710      -0.32914      2.143928     -0.373210     -0.373210   \n",
       "1        -0.493710      -0.32914      2.143928     -0.373210     -0.373210   \n",
       "2        -0.493710      -0.32914      2.143928     -0.373210     -0.373210   \n",
       "3        -0.493710      -0.32914      2.143928     -0.373210     -0.373210   \n",
       "4        -0.493710      -0.32914      2.143928     -0.373210     -0.373210   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2614     -0.301735       0.00000     -0.514315     -0.546859     -0.378455   \n",
       "2615      3.243652       0.00000     -0.514315     -0.546859     -0.378455   \n",
       "2616      3.243652       0.00000     -0.514315     -0.546859     -0.378455   \n",
       "2617      3.243652       0.00000     -0.514315     -0.546859     -0.378455   \n",
       "2618      3.243652       0.00000     -0.514315     -0.546859     -0.378455   \n",
       "\n",
       "      Time#DOW=SAT  Time#DOW=SUN  Time#WKD=Y  Time#WKD=N  Time#HRN=DAWN  ...  \\\n",
       "0        -0.373210     -0.414800   -0.608135    0.608135            0.0  ...   \n",
       "1        -0.373210     -0.414800   -0.608135    0.608135            0.0  ...   \n",
       "2        -0.373210     -0.414800   -0.608135    0.608135            0.0  ...   \n",
       "3        -0.373210     -0.414800   -0.608135    0.608135            0.0  ...   \n",
       "4        -0.373210     -0.414800   -0.608135    0.608135            0.0  ...   \n",
       "...            ...           ...         ...         ...            ...  ...   \n",
       "2614     -0.448067      2.184325    1.377054   -1.377054            0.0  ...   \n",
       "2615     -0.448067     -0.448067   -0.710737    0.710737            0.0  ...   \n",
       "2616     -0.448067     -0.448067   -0.710737    0.710737            0.0  ...   \n",
       "2617     -0.448067     -0.448067   -0.710737    0.710737            0.0  ...   \n",
       "2618     -0.448067     -0.448067   -0.710737    0.710737            0.0  ...   \n",
       "\n",
       "      ONF#ASC##ImmediatePast_15  ONF#RLV_SUP#ImmediatePast_15  \\\n",
       "0                      0.000000                      0.000000   \n",
       "1                      0.000000                      0.000000   \n",
       "2                      0.000000                      0.000000   \n",
       "3                      0.000000                      0.000000   \n",
       "4                      0.000000                      0.000000   \n",
       "...                         ...                           ...   \n",
       "2614                  -0.145865                      1.242816   \n",
       "2615                  -0.145865                      1.242816   \n",
       "2616                  -0.145865                      1.242816   \n",
       "2617                  -0.145865                     -0.805437   \n",
       "2618                  -0.145865                     -0.805437   \n",
       "\n",
       "      MED_VID#AVG#ImmediatePast_15  MED_VID#STD#ImmediatePast_15  \\\n",
       "0                              0.0                           0.0   \n",
       "1                              0.0                           0.0   \n",
       "2                              0.0                           0.0   \n",
       "3                              0.0                           0.0   \n",
       "4                              0.0                           0.0   \n",
       "...                            ...                           ...   \n",
       "2614                           0.0                           0.0   \n",
       "2615                           0.0                           0.0   \n",
       "2616                           0.0                           0.0   \n",
       "2617                           0.0                           0.0   \n",
       "2618                           0.0                           0.0   \n",
       "\n",
       "      MED_VID#SKW#ImmediatePast_15  MED_VID#KUR#ImmediatePast_15  \\\n",
       "0                              0.0                           0.0   \n",
       "1                              0.0                           0.0   \n",
       "2                              0.0                           0.0   \n",
       "3                              0.0                           0.0   \n",
       "4                              0.0                           0.0   \n",
       "...                            ...                           ...   \n",
       "2614                           0.0                           0.0   \n",
       "2615                           0.0                           0.0   \n",
       "2616                           0.0                           0.0   \n",
       "2617                           0.0                           0.0   \n",
       "2618                           0.0                           0.0   \n",
       "\n",
       "      MED_VID#ASC#ImmediatePast_15  MED_VID#BEP#ImmediatePast_15  \\\n",
       "0                              0.0                           0.0   \n",
       "1                              0.0                           0.0   \n",
       "2                              0.0                           0.0   \n",
       "3                              0.0                           0.0   \n",
       "4                              0.0                           0.0   \n",
       "...                            ...                           ...   \n",
       "2614                           0.0                           0.0   \n",
       "2615                           0.0                           0.0   \n",
       "2616                           0.0                           0.0   \n",
       "2617                           0.0                           0.0   \n",
       "2618                           0.0                           0.0   \n",
       "\n",
       "      MED_VID#MED#ImmediatePast_15  MED_VID#TSC#ImmediatePast_15  \n",
       "0                              0.0                           0.0  \n",
       "1                              0.0                           0.0  \n",
       "2                              0.0                           0.0  \n",
       "3                              0.0                           0.0  \n",
       "4                              0.0                           0.0  \n",
       "...                            ...                           ...  \n",
       "2614                           0.0                           0.0  \n",
       "2615                           0.0                           0.0  \n",
       "2616                           0.0                           0.0  \n",
       "2617                           0.0                           0.0  \n",
       "2618                           0.0                           0.0  \n",
       "\n",
       "[2619 rows x 571 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 values that are either infinity or negative infinity.\n"
     ]
    }
   ],
   "source": [
    "# Check for infinity or negative infinity\n",
    "is_inf = np.isinf(X)\n",
    "\n",
    "# Count how many are infinity or negative infinity\n",
    "count = is_inf.sum().sum()\n",
    "\n",
    "print(f\"There are {count} values that are either infinity or negative infinity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(X):\n",
    "    \"\"\"\n",
    "    Process the input DataFrame 'X':\n",
    "    1. Set column names as a range from 0 to the number of columns.\n",
    "    2. Replace boolean values with 1 for True and 0 for False.\n",
    "\n",
    "    Parameters:\n",
    "        X (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Set column names as a range from 0 to the number of columns\n",
    "    X.columns = range(X.shape[1])\n",
    "\n",
    "    # Replace boolean values with 1 for True and 0 for False\n",
    "    #     X = X * 1\n",
    "\n",
    "    return X\n",
    "def save_data_to_data_file(X, y, filename):\n",
    "    if not os.path.exists(PATH_SAVE):\n",
    "        os.makedirs(PATH_SAVE)\n",
    "\n",
    "    file_path = os.path.join(PATH_SAVE, filename)\n",
    "\n",
    "    with open(file_path, 'w') as f:\n",
    "        for i in range(len(X)):\n",
    "            line = str(y.iloc[i])  # get the value of the series\n",
    "            for col in X.columns:\n",
    "                line += \" {}:{}\".format(col, X[col].iloc[i])\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "def split_train_test(df, labels, indices):\n",
    "    test_X = df.loc[indices]\n",
    "    test_y = labels.loc[indices]\n",
    "    train_X = df.drop(indices)\n",
    "    train_y = labels.drop(indices)\n",
    "    return train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "for num_clusters in range(46):  # 46 is exclusive\n",
    "    PATH_SAVE = '/home/user/Collab/MT/logo/{}_clusters/data_MT'.format(num_clusters)\n",
    "    print(PATH_SAVE)\n",
    "\n",
    "    for turn in range(47):\n",
    "        # Select the current user (first one from the current PINFO_valid DataFrame)\n",
    "        selected = PINFO_valid.iloc[0:1]\n",
    "        # Remove the selected user from PINFO_valid\n",
    "        PINFO_valid = PINFO_valid.drop(selected.index)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        df = scaler.fit_transform(PINFO_valid)\n",
    "        #Clustering\n",
    "        kmeans = KMeans(n_clusters=num_clusters,init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "        pred_y = kmeans.fit_predict(df)\n",
    "        PINFO_valid.loc[:, 'cluster'] = pred_y\n",
    "    #     print(PINFO_valid)\n",
    "\n",
    "        #Calculate the cluster label of selected user\n",
    "        selected_scaled = scaler.fit_transform(selected)\n",
    "        selected_cluster = kmeans.predict(selected_scaled)\n",
    "        selected = selected.assign(cluster=selected_cluster)\n",
    "        PINFO_valid = pd.concat([PINFO_valid, selected])\n",
    "    #     print(selected_cluster)\n",
    "    #     print(selected)\n",
    "    #     print(\"___________________\")\n",
    "\n",
    "        #adding cluster label to feature space\n",
    "\n",
    "\n",
    "        # Convert groups to a pandas DataFrame\n",
    "        groups_df = pd.DataFrame(groups, columns=['pcode'])\n",
    "\n",
    "        # Create a new Series that maps Pcode to cluster label\n",
    "        cluster_map = PINFO_valid.set_index(PINFO_valid.index)['cluster']\n",
    "\n",
    "        # Create the 'cluster' column in the 'groups' DataFrame\n",
    "        groups_df['cluster'] = groups_df['pcode'].map(cluster_map)\n",
    "\n",
    "        # Add the 'cluster' column from 'groups_df' to 'X' as the first column\n",
    "        X.insert(0, 'cluster', groups_df['cluster'])\n",
    "\n",
    "        #saving data\n",
    "        matching_indices = []\n",
    "        for index, element in groups_df.iterrows():\n",
    "            if element['pcode'] == selected.index:\n",
    "                matching_indices.append(index)\n",
    "\n",
    "        # convert cluster_labels[y] into DataFrame with matching indices to cluster_dfs[y]\n",
    "        labels = pd.Series(y)\n",
    "        train_X, train_y, test_X, test_y = split_train_test(X, \n",
    "                                                            labels,\n",
    "                                                            matching_indices)\n",
    "        test_X = process_dataframe(test_X)\n",
    "        train_X = process_dataframe(train_X)\n",
    "        # Drop the first column for ST_XGboost\n",
    "    #     train_X = train_X.iloc[:, 1:]\n",
    "    #     test_X = test_X.iloc[:, 1:]\n",
    "\n",
    "        save_data_to_data_file(train_X, train_y, f'{turn}_train.data')\n",
    "        save_data_to_data_file(test_X, test_y, f'{turn}_val.data')\n",
    "\n",
    "        #reset to PINFO_valid\n",
    "        PINFO_valid = PINFO_valid.drop(columns=['cluster'])\n",
    "        X = X.drop(columns=['cluster'])\n",
    "    # print(PINFO_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data For ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "PATH_SAVE = '/home/user/Collab/MT/logo/data_ST3'\n",
    "for turn in range(47):\n",
    "    # Select the current user (first one from the current PINFO_valid DataFrame)\n",
    "    selected = PINFO_valid.iloc[0:1]\n",
    "    # Remove the selected user from PINFO_valid\n",
    "    PINFO_valid = PINFO_valid.drop(selected.index)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df = scaler.fit_transform(PINFO_valid)\n",
    "    #Clustering\n",
    "    kmeans = KMeans(n_clusters=38,init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    pred_y = kmeans.fit_predict(df)\n",
    "    PINFO_valid.loc[:, 'cluster'] = pred_y\n",
    "#     print(PINFO_valid)\n",
    "\n",
    "    #Calculate the cluster label of selected user\n",
    "    selected_scaled = scaler.fit_transform(selected)\n",
    "    selected_cluster = kmeans.predict(selected_scaled)\n",
    "    selected = selected.assign(cluster=selected_cluster)\n",
    "    PINFO_valid = pd.concat([PINFO_valid, selected])\n",
    "#     print(selected_cluster)\n",
    "#     print(selected)\n",
    "#     print(\"___________________\")\n",
    "\n",
    "    #adding cluster label to feature space\n",
    "\n",
    "\n",
    "    # Convert groups to a pandas DataFrame\n",
    "    groups_df = pd.DataFrame(groups, columns=['pcode'])\n",
    "\n",
    "    # Create a new Series that maps Pcode to cluster label\n",
    "    cluster_map = PINFO_valid.set_index(PINFO_valid.index)['cluster']\n",
    "\n",
    "    # Create the 'cluster' column in the 'groups' DataFrame\n",
    "    groups_df['cluster'] = groups_df['pcode'].map(cluster_map)\n",
    "\n",
    "    # Add the 'cluster' column from 'groups_df' to 'X' as the first column\n",
    "#     X.insert(0, 'cluster', groups_df['cluster'])\n",
    "\n",
    "    #saving data\n",
    "    matching_indices = []\n",
    "    for index, element in groups_df.iterrows():\n",
    "        if element['pcode'] == selected.index:\n",
    "            matching_indices.append(index)\n",
    "\n",
    "    # convert cluster_labels[y] into DataFrame with matching indices to cluster_dfs[y]\n",
    "    labels = pd.Series(y)\n",
    "    train_X, train_y, test_X, test_y = split_train_test(X, \n",
    "                                                        labels,\n",
    "                                                        matching_indices)\n",
    "    test_X = process_dataframe(test_X)\n",
    "    train_X = process_dataframe(train_X)\n",
    "#     Drop the first column for ST_XGboost\n",
    "#     train_X = train_X.iloc[:, 1:]\n",
    "#     test_X = test_X.iloc[:, 1:]\n",
    "\n",
    "    save_data_to_data_file(train_X, train_y, f'{turn}_train.data')\n",
    "    save_data_to_data_file(test_X, test_y, f'{turn}_val.data')\n",
    "\n",
    "    #reset to PINFO_valid\n",
    "    PINFO_valid = PINFO_valid.drop(columns=['cluster'])\n",
    "#     X = X.drop(columns=['cluster'])\n",
    "# print(PINFO_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
